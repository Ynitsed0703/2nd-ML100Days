{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "目前你應該已經要很清楚資料集中，資料的型態是什麼樣子囉！包含特徵 (features) 與標籤 (labels)。因此要記得未來不管什麼專案，必須要把資料清理成相同的格式，才能送進模型訓練。\n",
    "今天的作業開始踏入決策樹這個非常重要的模型，請務必確保你理解模型中每個超參數的意思，並試著調整看看，對最終預測結果的影響為何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 DecisionTreeClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將需要的都import進來\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import datetime          as dt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy                   import stats\n",
    "from itertools               import compress\n",
    "from sklearn.tree            import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics         import roc_curve,mean_squared_error,r2_score,accuracy_score,precision_score,recall_score,fbeta_score\n",
    "from sklearn.ensemble        import GradientBoostingRegressor,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.datasets        import load_boston, load_wine\n",
    "from sklearn.linear_model    import LogisticRegression,LinearRegression,Lasso,Ridge\n",
    "from sklearn.preprocessing   import LabelEncoder, MinMaxScaler, StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from IPython.display         import YouTubeVideo\n",
    "\n",
    "# 將較長的函式改名一下\n",
    "MSE  = mean_squared_error\n",
    "ACC  = accuracy_score\n",
    "MME  = MinMaxScaler()\n",
    "LE   = LabelEncoder()\n",
    "GBR  = GradientBoostingRegressor()\n",
    "GBC  = GradientBoostingClassifier()\n",
    "RFC  = RandomForestClassifier()\n",
    "OHE  = OneHotEncoder()\n",
    "\n",
    "# 一些必要的設定\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 設定【data的資料夾路徑】，命名為【data_folder】\n",
    "data_folder = 'C:/Users/Ynitsed/Documents/GitHub/2nd-ML100Days/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 連續型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "(506, 1)\n",
      "   target\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n"
     ]
    }
   ],
   "source": [
    "# 讀取 Boston 資料\n",
    "t001 = load_boston()\n",
    "# 轉成dataframe觀看資料：X\n",
    "train_X_t1 = pd.DataFrame(t001.data, columns=t001.feature_names)\n",
    "print(train_X_t1.shape)\n",
    "print(train_X_t1.head())\n",
    "# 轉成dataframe觀看資料：Y\n",
    "train_Y_t1 = pd.DataFrame({\"target\": t001.target})\n",
    "print(train_Y_t1.shape)\n",
    "print(train_Y_t1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 13)\n",
      "        CRIM   ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
      "169  2.44953  0.0  19.58   0.0  0.605  6.402   95.2  2.2625   5.0  403.0   \n",
      "402  9.59571  0.0  18.10   0.0  0.693  6.404  100.0  1.6390  24.0  666.0   \n",
      "295  0.12932  0.0  13.92   0.0  0.437  6.678   31.1  5.9604   4.0  289.0   \n",
      "134  0.97617  0.0  21.89   0.0  0.624  5.757   98.4  2.3460   4.0  437.0   \n",
      "117  0.15098  0.0  10.01   0.0  0.547  6.021   82.6  2.7474   6.0  432.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "169     14.7  330.04  11.32  \n",
      "402     20.2  376.11  20.31  \n",
      "295     16.0  396.90   6.27  \n",
      "134     21.2  262.76  17.31  \n",
      "117     17.8  394.51  10.30  \n",
      "(455, 1)\n",
      "     target\n",
      "169    22.3\n",
      "402    12.1\n",
      "295    28.6\n",
      "134    15.6\n",
      "117    19.2\n",
      "(51, 13)\n",
      "        CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
      "8    0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
      "289  0.04297  52.5   5.32   0.0  0.405  6.565   22.9  7.3172  6.0  293.0   \n",
      "68   0.13554  12.5   6.07   0.0  0.409  5.594   36.8  6.4980  4.0  345.0   \n",
      "211  0.37578   0.0  10.59   1.0  0.489  5.404   88.6  3.6650  4.0  277.0   \n",
      "226  0.38214   0.0   6.20   0.0  0.504  8.040   86.5  3.2157  8.0  307.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "8       15.2  386.63  29.93  \n",
      "289     16.6  371.72   9.51  \n",
      "68      18.9  396.90  13.09  \n",
      "211     18.6  395.24  23.98  \n",
      "226     17.4  387.38   3.13  \n",
      "(51, 1)\n",
      "     target\n",
      "8      16.5\n",
      "289    24.8\n",
      "68     17.4\n",
      "211    19.3\n",
      "226    37.6\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_X_t1, train_Y_t1, test_size=0.1, random_state=4)\n",
    "# 看切完長怎樣\n",
    "print(x_train.shape)\n",
    "print(x_train.head())\n",
    "print(y_train.shape)\n",
    "print(y_train.head())\n",
    "print(x_test.shape)\n",
    "print(x_test.head())\n",
    "print(y_test.shape)\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11567831  0.05152311 -0.03346275  1.2230427  -0.          3.53216363\n",
      " -0.00922692 -1.19460642  0.28775344 -0.01473748 -0.75732817  0.01037228\n",
      " -0.58007751]\n",
      "[26.51430651]\n",
      "0.7213721091124857\n",
      "(51,)\n",
      "           0\n",
      "0  10.564299\n",
      "1  26.448298\n",
      "2  16.872990\n",
      "3  14.403291\n",
      "4  36.824084\n",
      "Mean squared error: 18.19\n"
     ]
    }
   ],
   "source": [
    "# LASSO\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "LAS  = Lasso(alpha=0.1)\n",
    "LAS.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "print(LAS.coef_)\n",
    "print(LAS.intercept_)\n",
    "print(LAS.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = LAS.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.25305527e-01  4.85968956e-02  1.35490467e-02  3.05965839e+00\n",
      "  -1.61558736e+01  3.62646355e+00  1.10808781e-03 -1.47693015e+00\n",
      "   3.17043498e-01 -1.28048402e-02 -9.15220623e-01  9.56698213e-03\n",
      "  -5.35070934e-01]]\n",
      "[36.24753622]\n",
      "0.7343810440447924\n",
      "(51, 1)\n",
      "           0\n",
      "0  11.393837\n",
      "1  26.774051\n",
      "2  17.388518\n",
      "3  17.434389\n",
      "4  37.356057\n",
      "Mean squared error: 17.07\n"
     ]
    }
   ],
   "source": [
    "# RIDGE\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "RIG  = Ridge(alpha=0.1)\n",
    "RIG.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "print(RIG.coef_)\n",
    "print(RIG.intercept_)\n",
    "print(RIG.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = RIG.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.25856659e-01  4.84257396e-02  1.84085281e-02  3.08509569e+00\n",
      "  -1.73277018e+01  3.61674713e+00  2.19181853e-03 -1.49361132e+00\n",
      "   3.19979200e-01 -1.27294649e-02 -9.27469086e-01  9.50912468e-03\n",
      "  -5.33592471e-01]]\n",
      "[37.06602854]\n",
      "0.734430389314123\n",
      "(51, 1)\n",
      "           0\n",
      "0  11.460308\n",
      "1  26.802693\n",
      "2  17.434789\n",
      "3  17.556310\n",
      "4  37.391564\n",
      "Mean squared error: 17.04\n"
     ]
    }
   ],
   "source": [
    "# LIR\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "LIR = LinearRegression()\n",
    "LIR.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "print(LIR.coef_)\n",
    "print(LIR.intercept_)\n",
    "print(LIR.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = LIR.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "(51,)\n",
      "      0\n",
      "0  23.7\n",
      "1  24.5\n",
      "2  19.3\n",
      "3  21.7\n",
      "4  48.3\n",
      "Mean squared error: 22.67\n"
     ]
    }
   ],
   "source": [
    "# DTR\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "DTR = DecisionTreeRegressor()\n",
    "DTR.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "# print(DTR.coef_)\n",
    "# print(DTR.intercept_)\n",
    "print(DTR.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = DTR.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非連續型、分類(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  \n",
      "0                          3.92   1065.0  \n",
      "1                          3.40   1050.0  \n",
      "2                          3.17   1185.0  \n",
      "3                          3.45   1480.0  \n",
      "4                          2.93    735.0  \n",
      "(178, 1)\n",
      "   target\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "# 讀取 wine 資料\n",
    "t002 = load_wine()\n",
    "# 轉成dataframe觀看資料：X\n",
    "train_X_t1 = pd.DataFrame(t002.data, columns=t002.feature_names)\n",
    "print(train_X_t1.shape)\n",
    "print(train_X_t1.head())\n",
    "# 轉成dataframe觀看資料：Y\n",
    "train_Y_t1 = pd.DataFrame({\"target\": t002.target})\n",
    "print(train_Y_t1.shape)\n",
    "print(train_Y_t1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 13)\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "93     12.29        2.83  2.22               18.0       88.0           2.45   \n",
      "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
      "91     12.00        1.51  2.42               22.0       86.0           1.45   \n",
      "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
      "124    11.87        4.31  2.39               21.0       82.0           2.86   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "93         2.25                  0.25             1.99             2.15  1.15   \n",
      "156        0.83                  0.48             1.56             9.01  0.57   \n",
      "91         1.25                  0.50             1.63             3.60  1.05   \n",
      "165        0.47                  0.52             1.15             6.62  0.78   \n",
      "124        3.03                  0.21             2.91             2.80  0.75   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "93                           3.30    290.0  \n",
      "156                          1.64    480.0  \n",
      "91                           2.65    450.0  \n",
      "165                          1.75    520.0  \n",
      "124                          3.64    380.0  \n",
      "(160, 1)\n",
      "     target\n",
      "93        1\n",
      "156       2\n",
      "91        1\n",
      "165       2\n",
      "124       1\n",
      "(18, 13)\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
      "142    13.52        3.17  2.72               23.5       97.0           1.55   \n",
      "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
      "45     14.21        4.04  2.44               18.9      111.0           2.85   \n",
      "81     12.72        1.81  2.20               18.8       86.0           2.20   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "163        0.70                  0.40             0.94             5.28  0.68   \n",
      "142        0.52                  0.50             0.55             4.35  0.89   \n",
      "14         3.64                  0.29             2.96             7.50  1.20   \n",
      "45         2.65                  0.30             1.25             5.24  0.87   \n",
      "81         2.53                  0.26             1.77             3.90  1.16   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "163                          1.75    675.0  \n",
      "142                          2.06    520.0  \n",
      "14                           3.00   1547.0  \n",
      "45                           3.33   1080.0  \n",
      "81                           3.14    714.0  \n",
      "(18, 1)\n",
      "     target\n",
      "163       2\n",
      "142       2\n",
      "14        0\n",
      "45        0\n",
      "81        1\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_X_t1, train_Y_t1, test_size=0.1, random_state=4)\n",
    "# 看切完長怎樣\n",
    "print(x_train.shape)\n",
    "print(x_train.head())\n",
    "print(y_train.shape)\n",
    "print(y_train.head())\n",
    "print(x_test.shape)\n",
    "print(x_test.head())\n",
    "print(y_test.shape)\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.88852656e-01  6.67300827e-01  1.00960693e+00 -5.80989219e-01\n",
      "  -3.55178256e-02  3.62071144e-01  1.18894658e+00  3.78340624e-03\n",
      "  -4.54784892e-01 -1.53560698e-01 -1.62107824e-01  9.11550191e-01\n",
      "   1.77906683e-02]\n",
      " [ 9.31771389e-01 -1.08459849e+00 -7.53390627e-01  2.41931110e-01\n",
      "   1.24181909e-02  3.53858216e-02  5.76719638e-01  5.39359650e-01\n",
      "   6.06710292e-01 -1.86151560e+00  9.52831552e-01  7.69014213e-02\n",
      "  -1.44579779e-02]\n",
      " [-3.44877619e-01  6.57378630e-01  3.90432260e-02  1.20175740e-01\n",
      "   1.94696375e-02 -6.60620544e-01 -1.84324382e+00 -9.24618142e-02\n",
      "  -6.79666411e-01  1.08773341e+00 -4.94768310e-01 -1.20152083e+00\n",
      "   2.92068606e-04]]\n",
      "[-0.31382295  0.40776435 -0.07676462]\n",
      "0.975\n",
      "(18,)\n",
      "   0\n",
      "0  2\n",
      "1  2\n",
      "2  0\n",
      "3  0\n",
      "4  1\n",
      "Mean squared error: 0.06\n",
      "Accuracy:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# LGR\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "LGR = LogisticRegression()\n",
    "LGR.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "print(LGR.coef_)\n",
    "print(LGR.intercept_)\n",
    "print(LGR.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = LGR.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))\n",
    "# 本例中直接分成了0,1,2，屬於classification tasks，可以使用ACC。\n",
    "print(\"Accuracy: \", ACC(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "(18,)\n",
      "   0\n",
      "0  2\n",
      "1  2\n",
      "2  0\n",
      "3  0\n",
      "4  1\n",
      "Mean squared error: 0.11\n",
      "Accuracy:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# DTC\n",
    "# 跑完背後就已經有整個回歸模型了\n",
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(x_train, y_train)\n",
    "# 印出coef\n",
    "# print(DTC.coef_)\n",
    "# print(DTC.intercept_)\n",
    "print(DTC.score(x_train, y_train))\n",
    "# 將x_test丟進上面跑好的回歸模型裡，得到y_pred，也就是預測出來的y_pred。\n",
    "y_pred = DTC.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "print(pd.DataFrame(y_pred).head())\n",
    "# 看一下預測出來的y_pred和實際的y_test差多少？\n",
    "print(\"Mean squared error: %.2f\"% MSE(y_test, y_pred))\n",
    "# 本例中直接分成了0,1,2，屬於classification tasks，可以使用ACC。\n",
    "print(\"Accuracy: \", ACC(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
